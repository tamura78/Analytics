{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\requests\\__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.14) or chardet (3.0.4) doesn't match a supported version!\n",
      "  RequestsDependencyWarning)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#関数１\n",
    "def joblib_get_url(i):\n",
    "    url_list_pre=list()\n",
    "    url=url_list_001[i]\n",
    "    raw_url=\"https://www.baitoru.com\"\n",
    "    res=requests.get(url)\n",
    "    soup=BeautifulSoup(res.text,\"html.parser\")\n",
    "    for i in range(0,20):\n",
    "        try:\n",
    "            elem = soup.find_all(\"article\", class_=\"list-jobListDetail\")[i].find(\"h3\").find(\"a\")\n",
    "            url_key=elem.attrs[\"href\"] #hrefの値(url)のみを抜き取る\n",
    "            n_url_key=raw_url+url_key\n",
    "            url_list_pre.append(n_url_key)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    return url_list_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#関数2\n",
    "def joblib_get_data(i):\n",
    "    new_list=list()\n",
    "    houjin=syokusyu=kyuyo=''\n",
    "    \n",
    "    url = url_list_003[i]\n",
    "    res = requests.get(url)\n",
    "    soup=BeautifulSoup(res.text,\"html.parser\")\n",
    "    \n",
    "    try:\n",
    "        selector=\"#contents > div.layout-grid-2-2 > div.layout-column-1 > div > div.detail-companyInfo > div > div.bg01 > div.pt02 > dl > dd > p\"\n",
    "        raw_houjin=soup.select_one(selector).get_text()\n",
    "        houjin=raw_houjin.split()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    for i in range(0, 10):\n",
    "        try:\n",
    "            judge = soup.find(\"div\", class_=\"detail-basicInfo\").find_all(\"dt\")[i].get_text()\n",
    "            if \"職種\" in judge:\n",
    "                pre_syokusyu = soup.find(\"div\", class_=\"detail-basicInfo\").find_all(\"dd\")[i].get_text()\n",
    "                syokusyu = pre_syokusyu.split()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for i in range(0, 10):\n",
    "        try:\n",
    "            judge = soup.find(\"div\", class_=\"detail-basicInfo\").find_all(\"dt\")[i].get_text()\n",
    "            if \"給与\" in judge:\n",
    "                pre_kyuyo = soup.find(\"div\", class_=\"detail-basicInfo\").find_all(\"dd\")[i].get_text()\n",
    "                kyuyo = pre_kyuyo.split()\n",
    "        except:\n",
    "            pass  \n",
    "    \n",
    "    new_list.append(houjin)\n",
    "    new_list.append(syokusyu)\n",
    "    new_list.append(kyuyo)\n",
    "\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,173\n"
     ]
    }
   ],
   "source": [
    "url=\"https://www.baitoru.com/kanto/jlist/tokyo/conveni/\"\n",
    "res=requests.get(url)\n",
    "soup=BeautifulSoup(res.text,\"html.parser\")\n",
    "total_num_str_pre=soup.find(id=\"js-job-count\").get_text()\n",
    "\n",
    "print(total_num_str_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2173\n"
     ]
    }
   ],
   "source": [
    "total_num_str=total_num_str_pre.replace(\",\",\"\")\n",
    "total_num=int(total_num_str)\n",
    "print(total_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109\n"
     ]
    }
   ],
   "source": [
    "total_page_num=total_num//20+1\n",
    "print(total_page_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_001=list()\n",
    "url_list_001.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=10\n",
    "joblib_num=total_page_num//a+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s][Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done   3 out of  10 | elapsed:    2.0s remaining:    4.7s\n",
      "[Parallel(n_jobs=12)]: Done   7 out of  10 | elapsed:    2.2s remaining:    0.9s\n",
      "100%|██████████| 1/1 [00:08<00:00,  8.28s/it]\n"
     ]
    }
   ],
   "source": [
    "url_list_002=list()\n",
    "for n in tqdm(range(0,joblib_num)):\n",
    "    try:\n",
    "        resultList = joblib.Parallel(n_jobs=12, verbose=3)( [joblib.delayed(joblib_get_url)(i) for i in range(n*a,(n+1)*a)])\n",
    "        url_list_002.extend(resultList)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list_002_filtered=[x for x in url_list_002 if x is not None]\n",
    "flatten_url_list_002 = [ flatten for inner in url_list_002_filtered for flatten in inner ]#難しい(ノンローカル変数)\n",
    "url_list_003 = []\n",
    "for i in flatten_url_list_002:\n",
    "    if i not in url_list_003:\n",
    "        url_list_003.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=100\n",
    "joblib_num = len(url_list_003)//b + 1\n",
    "\n",
    "all_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s][Parallel(n_jobs=12)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.26s/it]\n"
     ]
    }
   ],
   "source": [
    "for n in tqdm(range(0, joblib_num)):\n",
    "    try:\n",
    "        resultList = joblib.Parallel(n_jobs=12, verbose=3)( [joblib.delayed(joblib_get_data)(i) for i in range(n*b,(n+1)*b)])\n",
    "        all_list.extend(resultList)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten_list = [ flatten for inner in all_list for flatten in inner ]\n",
    "all_list_filtered = [x for x in all_list if x is not None]\n",
    "kekka = pd.DataFrame(all_list_filtered,columns=[\"法人名\",\"職種\",\"給与情報\"])\n",
    "\n",
    "\n",
    "kekka.to_csv('second.csv',encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データの格納\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'year' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1bb13e5b5b95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'データの格納'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mbucket_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'monthly-scraping'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0ms3_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'monthly_data/{}年/{}月/媒体名.csv'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0ms3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mboto3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m's3'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'year' is not defined"
     ]
    }
   ],
   "source": [
    "print('データの格納')\n",
    "bucket_name = 'monthly-scraping'\n",
    "s3_key = 'monthly_data/{}年/{}月/媒体名.csv'.format(year,month)\n",
    "s3 = boto3.resource('s3') \n",
    "\n",
    "s3_obj = s3.Object(bucket_name,s3_key)\n",
    "s3_obj.put(Body=kekka.to_csv(None).encode('utf_8_sig'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
